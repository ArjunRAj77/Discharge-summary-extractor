{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjunRAj77/Discharge-summary-extractor/blob/main/Discharge_Summary_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discharge Summary Extractor\n",
        "\n",
        "A streamlit application which uses to identify various problems and medications provided in the 'input discharge summary PDF ' using NLP model , deployed using Google Collab.\n",
        "\n",
        "\n",
        "We will start with installing required libraries and modules:\n",
        "- ngrok \n",
        "- streamlit\n",
        "- pyPDF2\n",
        "- medspacy [0.2.0.1]\n"
      ],
      "metadata": {
        "id": "sI1AYZPx4rm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ngrok"
      ],
      "metadata": {
        "id": "XUlRcnVJRyzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we need to deploy streamlit application in web, we require a tunneling service to forward the port link.\n",
        "\n",
        "Firstly it needs to be connected to your application using auth token!\n",
        "\n",
        "for reference: [Deploying streamlit application from Google Collab](https://faun.dev/c/stories/neji_14/how-to-create-and-launch-a-streamlit-app-directly-from-google-colab/)"
      ],
      "metadata": {
        "id": "0xxHcNbe5Cx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok authtokens 2I25bavkwHYELR9tekrQDh8hpX7_e4JXyMTiF1UdcvBXdF7n"
      ],
      "metadata": {
        "id": "5rWUupGgR2t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "mma6RTWWR5LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "metadata": {
        "id": "bphD3AQtR7h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "HofzNGHuR98Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyPDF2"
      ],
      "metadata": {
        "id": "PZEoZ-u9SA9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy_streamlit"
      ],
      "metadata": {
        "id": "1SxL19tBSELe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install medspacy==0.2.0.1"
      ],
      "metadata": {
        "id": "2C6fgxaRSUPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the dependant libraries and modules are installed, we can directly write the necessary code for streamlit application.\n",
        "\n",
        "Note: upload the datasets [ druglist.csv and diseaselist.csv] to the Files section in Google Collab."
      ],
      "metadata": {
        "id": "3d2aL5XN5kyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "\n",
        "\n",
        "# Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import spacy_streamlit\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from PyPDF2 import PdfReader\n",
        "import medspacy\n",
        "from medspacy.ner import TargetRule\n",
        "from medspacy.visualization import visualize_ent\n",
        "from spacy_streamlit import visualize_parser\n",
        "\n",
        "\n",
        "st.title('Discharge Summary Extractor')\n",
        "uploaded_file = st.file_uploader(\"Choose a file\")\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def loading_ml_model(): \n",
        "\n",
        "  #problemlist=[\"allergies\",\"asthma\",\"diabetes\"]\n",
        "  #medilist=[\"Claritin\",\"Zyrtec\",\"Ortho Tri-Cyclen\",\"Allegra\"]\n",
        "\n",
        "  #Getting disease list\n",
        "  diseasedf = pd.read_csv('/content/diseasedataset.csv')\n",
        "  diseaselist = diseasedf['diseasename'].tolist()\n",
        "  print(\"Completed loading disease dataset.\")\n",
        "\n",
        "  # Getting drug list\n",
        "  drugdf = pd.read_csv('/content/drugdataset.csv')\n",
        "  druglist = drugdf['drugName'].tolist()\n",
        "  dglist=[]\n",
        "\n",
        "  # Here we are only using 2000 drugs names as input to maintain \n",
        "  for x in druglist[:2000]:\n",
        "      dglist.append(x)\n",
        "  print(\"Completed loading drug dataset.\")\n",
        "\n",
        "  \n",
        "  # Load medspacy model\n",
        "\n",
        "  nlp = medspacy.load()\n",
        "  print(nlp.pipe_names)\n",
        "  print(\"Started adding rules to nlp model..........\")\n",
        "  # Add rules for target concept extraction\n",
        "  target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
        "  for i in diseaselist:\n",
        "    for j in dglist:\n",
        "      target_rules = [\n",
        "        TargetRule(i, \"PROBLEM\"),  \n",
        "        TargetRule(j, \"MEDICATION\")\n",
        "            ]\n",
        "      target_matcher.add(target_rules)\n",
        "  print(\"Completed making rules in nlp model\")\n",
        "  return nlp\n",
        "\n",
        "def post_processing(doc):\n",
        "\n",
        "    problem_label=[]\n",
        "    medication_label=[]\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_=='PROBLEM':\n",
        "          problem_label.append(ent)\n",
        "        if ent.label_=='MEDICATION':\n",
        "          medication_label.append(ent) \n",
        "    print(problem_label)\n",
        "    print(medication_label)\n",
        "    prob_len=len(problem_label)\n",
        "    med_len=len(medication_label)\n",
        "    st.subheader(\"Summary:\")\n",
        "    st.write(f\" Total number of identified diseases/problems in the file : {prob_len}\")\n",
        "    st.write(f\" Total number of identified medications prescribed in the file : {med_len}\")\n",
        "    pass\n",
        "\n",
        "if(uploaded_file is not None):\n",
        "  reader = PdfReader(uploaded_file)\n",
        "  print(\"Successfully read the file!\")\n",
        "  nlp=loading_ml_model()\n",
        "  print(\"Completed loading the NLP model.\")\n",
        "  st.markdown('**Successfully loaded NLP model.**')\n",
        "  if st.button('Extract'):\n",
        "    st.subheader('Extracted Data:')\n",
        "    st.markdown('Note: _The  first page of PDF is only considered for processing_!')\n",
        "    number_of_pages = len(reader.pages)\n",
        "    page = reader.pages[0]\n",
        "    text_data = page.extract_text()\n",
        "\n",
        "    # Processing Data with nlp model\n",
        "\n",
        "    doc = nlp(text_data)\n",
        "    print(\"Extracted the data.\")\n",
        "\n",
        "    # Adding colors to the rules\n",
        "    colors = {\"PROBLEM\": \"orange\", \"MEDICATION\": \"green\"}\n",
        "    options = {\"colors\": colors}\n",
        "    visualize_ent(doc)\n",
        "    print(\"Starting visualization of the data....\")\n",
        "\n",
        "    # Visualization of extracted data\n",
        "    html =displacy.render(doc, style=\"ent\", page=True,options=options)\n",
        "    st.components.v1.html(html, width=1000, height=1000, scrolling=True)\n",
        "    print(\"Visualization Completed.\")\n",
        "    print(\"Calling post processing function\")\n",
        "    post_processing(doc)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsRekC2eSIhj",
        "outputId": "b86c625f-f865-4f1a-d332-7a44621cbdd4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following command to deploy the streamlit app. \n",
        "\n",
        "It will produce a tunneling link, so that streamlit application can be accessed via internet."
      ],
      "metadata": {
        "id": "80PZgSsu5vsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/streamlit_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "vQQcK49uSv5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}