{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFCaIc/YcaxD21lV0Ol/qJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjunRAj77/Discharge-summary-extractor/blob/main/ICD10_identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ICD 10 Extractor**\n",
        "\n",
        "Training a machine learning model to accurately identify ICD-10 codes in sentences is a complex task that requires a good understanding of both machine learning and the ICD-10 coding system. \n",
        "\n",
        "To build a model like this, you would need a large dataset of sentences that have been labeled with the correct ICD-10 codes, as well as a machine learning algorithm that can learn to map the sentences to the correct codes. You would then need to train the model on your dataset, using techniques like feature engineering and hyperparameter tuning to optimize its performance. \n",
        "\n",
        "It's also important to evaluate the model's performance on a separate test dataset to ensure it is accurate and reliable.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Collecting and preparing a dataset of labeled examples (i.e., sentences and their corresponding ICD-10 codes).\n",
        "2. Choosing a machine learning algorithm and implementing it in code.\n",
        "3. Training the model on the dataset using techniques like feature engineering and hyperparameter tuning.\n",
        "4. Evaluating the model's performance on a separate test dataset to ensure it is accurate and reliable."
      ],
      "metadata": {
        "id": "0_Ax_a1WRWD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 : Collecting Data for dataset creation.**\n",
        "\n",
        "Since we are dealing with sensitive data, we need a reliable source of information.\n",
        "- One possible source of this information is the World Health Organization (WHO), which maintains a database of ICD-10 codes and their corresponding descriptions.\n",
        "-  collect this information from medical records or other healthcare databases.\n",
        "\n",
        "\n",
        "The dataset we have generated for the usability of the ML model is :\n",
        "\n",
        " https://www.kaggle.com/datasets/mrhell/icd10cm-codeset-2023"
      ],
      "metadata": {
        "id": "-HjUCRpyRlNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 :  Choosing a machine learning algorithm and implementing it in code**.\n",
        "\n",
        "This is the most trickier part. Since we are dealing with NER and text classification, a proper NLP should be models can be used:\n",
        "- **RNN**\n",
        "- **Transformer** \n",
        "\n",
        "Here we will be using Spacy modules for NER identification.\n",
        "\n",
        "***spaCy*** is a popular natural language processing (NLP) library for Python. It provides tools and libraries for performing a variety of NLP tasks, such as tokenization, part-of-speech tagging, named entity recognition, and more.\n",
        "\n",
        "The ***Matcher*** class in spaCy allows you to create and match patterns in text. A pattern is a list of dictionaries that defines the sequence of tokens and the conditions or constraints on the tokens that should be matched in the text. For example, a pattern can specify that a specific word or phrase should be matched, or that the text matched by the pattern should be optional, occur at least a certain number of times, or be in a specific part of speech.\n",
        "\n",
        "Once you have created a pattern using the Matcher class, you can use the matcher object to match the pattern against a text. This will return a list of matches, where each match is a tuple consisting of the label of the pattern, the start and end indices of the match in the text, and the span of the match."
      ],
      "metadata": {
        "id": "fOeNcZq1RtpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ngrok"
      ],
      "metadata": {
        "id": "W-N-2xPeRDvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "fswqH02aRM3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "BFXabC67RPQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy"
      ],
      "metadata": {
        "id": "dZayIZMnRQ7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py \n",
        "import streamlit as st\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy import displacy\n",
        "import re\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create the pattern using the Matcher class\n",
        "matcher = Matcher(nlp.vocab)\n",
        "ICDDescription=['Cholera','Cholera due to Vibrio cholerae 01, biovar cholerae Cholera due to Vibrio cholerae 01, biovar cholerae','Cholera due to Vibrio cholerae 01, biovar eltor Cholera due to Vibrio cholerae 01, biovar eltor']\n",
        "ICDcode=['A00','A000','A001']\n",
        "for sentence in ICDDescription:\n",
        "  words = re.findall(r'\\b\\w+\\b', sentence) # selecting only the words, omitting the special characters\n",
        "pattern = [{'OP': '?'}, {'TEXT': 'google'}, {'OP': '*'}, {'TEXT': 'inc.'}]\n",
        "matcher.add('GoogleIncPattern',[pattern])\n",
        "# google_pattern = [{'TEXT': 'Google'}, {'OP': '*'}, {'TEXT': 'Inc.'}]\n",
        "# matcher.add('GoogleIncPattern',[google_pattern])\n",
        "\n",
        "# apple_pattern = [{'TEXT': 'Apple'}, {'OP': '*'}, {'TEXT': 'Inc.'}]\n",
        "# matcher.add('AppleIncPattern',[apple_pattern])\n",
        "\n",
        "# Use the streamlit text_area widget to allow the user to enter a text\n",
        "text = st.text_area('Enter a text:')\n",
        "\n",
        "# Parse the text with spaCy and use the pattern to find named entities\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Set the colors for different named entity types\n",
        "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)'}\n",
        "options = {'ents': ['ORG'], 'colors': colors}\n",
        "\n",
        "# Visualize the named entities in the text\n",
        "st.markdown(displacy.render(doc, style='ent', options=options), unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "pigwljLMRVI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/streamlit_app.py & npx localtunnel --port 8501 "
      ],
      "metadata": {
        "id": "yrQFyLPGSUJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJE4Ce-GUCjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HB5HsycKVNuS"
      }
    }
  ]
}